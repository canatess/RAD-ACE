# ğŸ¥ RAD-ACE: MLLMs AS RADIOLOGY ASSISTANTS

### ğŸ“Œ CMP719 Computer Vision Project  
#### âœï¸ Authors: **Can Ali ATEÅ, Emre Ã‡OBAN, Abdullah Enes ERGÃœN**  

## ğŸ§ Overview  
**RAD-ACE** is a cutting-edge research project designed to **fine-tune vision-language large language models (VLLMs)** for **structured medical report generation**. By integrating advanced **computer vision** with **language models**, it aims to produce **accurate, coherent, and context-aware** medical analyses.  

This project focuses on enhancing the **logical structuring** of AI-generated reports, ensuring **interpretability, clinical reliability, and consistency** in diagnostic documentation.  

## ğŸ§  Models Used  
_(Detailed descriptions can be added later for each model.)_  
- ğŸ”¹ **Qwen 2.5 VL-3B**: Lightweight VLM used for efficient inference and baseline evaluation on vision-language tasks.  
- ğŸ”¹ **Qwen 2.5 VL-7B**: Larger variant for improved multimodal reasoning and image-text alignment. 
- ğŸ”¹ **LLaMA 3.2 Vision - 11B**: High-capacity model used for advanced multimodal understanding, including visual question answering and report generation. 

## ğŸ“‚ Dataset Sources  
_(Links will be added for each dataset source.)_  
- ğŸ”— **Dataset 1**: [[PubMedVision](https://huggingface.co/datasets/FreedomIntelligence/PubMedVision)]  
- ğŸ”— **Dataset 2**: [[VQA-RAD](https://huggingface.co/datasets/flaviagiammarino/vqa-rad)]  

## ğŸ“„ Research Paper  
For detailed insights into our methodology and findings, refer to our research paper:  
ğŸ“Œ **[Paper Title]** â€“ [Paper Link]  

## âš™ï¸ Installation & Usage  
1ï¸âƒ£ **Clone the repository:**  
   ```bash
   git clone https://github.com/canatess/RAD-ACE.git
